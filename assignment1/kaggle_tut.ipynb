{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "Kaggle's **Titanic - Machine Learning from Disaster** is a classic introductory problem for getting familiar with the fundamentals of machine learning.\n",
    "In this notebook..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Where to start?**\n",
    "\n",
    "https://www.kaggle.com/code/alexisbcook/titanic-tutorial/notebook\n",
    "\n",
    "Alexis provides a brief introduction for making a submission to kaggle with some sample code for this challenge. She uses a random forest classifier for the model in her example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "\n",
    "PATH = \"../input/titanic/\" # file path to the datasets\n",
    "\n",
    "for dirname, _, filenames in os.walk('PATH'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(PATH + \"train.csv\")\n",
    "test_data = pd.read_csv(PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model_orignial = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model_orignial.fit(X, y)\n",
    "predictions = model_orignial.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The submission of this model resulted in a score of 0.77511"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Contribution**\n",
    "<!-- We can start with this as our baseline and change a few things to see if we \n",
    "get a better result. The first and easisest thing to do is tune the hyperparameters for the Random Forest Classifier and compare the results with the original submission. -->\n",
    "### Part 1\n",
    "We can start by looking for entries in the dataset to dropout or modify to improve the performance of the model. The passenger ID contains a unique and non-null value which means that there will be no duplicates to drop. There are missing values in other columns that we can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1309\n",
      "\n",
      "Age          263\n",
      "Fare           1\n",
      "Cabin       1014\n",
      "Embarked       2\n",
      "Name: by amount, dtype: int64         \n",
      "\n",
      "Age         20.09 \n",
      "Fare         0.08 \n",
      "Cabin       77.46 \n",
      "Embarked     0.15 \n",
      "Name: by percent, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_list = [train_data.drop(\"Survived\", axis=1), test_data]\n",
    "for i, dl in enumerate(data_list):\n",
    "        data_list[i].Sex = dl.Sex.apply(lambda sex: 0 if sex == \"male\" else 1)\n",
    "all_data = pd.concat(data_list)\n",
    "\n",
    "missing_vals = [all_data[col].isnull().sum() for col in all_data.columns.to_list()]\n",
    "labels = all_data.columns.to_list()\n",
    "ser = pd.Series(data=missing_vals, index=labels, name=\"by amount\")\n",
    "ser_missing = ser[ser > 0]\n",
    "\n",
    "percentages = ser_missing.apply(lambda x: \"%.2f \" % (x * 100 / all_data.shape[0]))\n",
    "percentages.name = \"by percent\"\n",
    "print(f\"Total number of rows: {all_data.shape[0]}\\n\\n{ser_missing} \\\n",
    "        \\n\\n{percentages}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of missing values for `Fare` and `Embarked` column is negligible, it is best to simply drop these entries from the dataset. However there are a considerable amount of missing values for the `Age` and `Cabin` columns. A naive approach for filling in the missing values for the `Age` column would be to fill them in with the mean or median of the column. The better approach is to look at the relationships between `Age` and the other columns, then determine the filler value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.026757\n",
       "Pclass        -0.409082\n",
       "Sex           -0.066006\n",
       "Age            1.000000\n",
       "SibSp         -0.242345\n",
       "Parch         -0.149311\n",
       "Fare           0.177206\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, dl in enumerate(data_list):\n",
    "    data_list[i] = dl[dl[\"Fare\"].notna() & dl[\"Embarked\"].notna()]\n",
    "all_data = all_data[all_data[\"Fare\"].notna() & all_data[\"Embarked\"].notna()]\n",
    "\n",
    "# corr = corr.iloc[1:, 1:]x\n",
    "# corr.style.background_gradient(cmap='coolwarm', axis=None).format(precision=2)\n",
    "corr = all_data.corr().loc[\"Age\"]\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pclass` appears to have a high influence on `Age` while sex has virtually no impact on `Age`. This information can be applied to extract finer approximations based on the `Pclass` to better suit the missing entries as opposed to a \"one fits all\" approximation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
