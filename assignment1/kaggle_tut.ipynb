{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "Kaggle's **Titanic - Machine Learning from Disaster** is a classic introductory problem for getting familiar with the fundamentals of machine learning. Here's a quick run-through on how I tuned some features to improve a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Where to start?**\n",
    "\n",
    "https://www.kaggle.com/code/alexisbcook/titanic-tutorial/notebook\n",
    "\n",
    "Alexis provides a brief introduction for making a submission to kaggle with some sample code for this challenge. She uses a random forest classifier for the model in her example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os\n",
    "\n",
    "PATH = \"../input/titanic/\" # file path to the datasets\n",
    "\n",
    "for dirname, _, filenames in os.walk('PATH'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Datasets\n",
    "train_data = pd.read_csv(PATH + \"train.csv\")\n",
    "test_data = pd.read_csv(PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(train_data[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The submission of this model resulted in a score of 0.77511"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Contribution**\n",
    "<!-- We can start with this as our baseline and change a few things to see if we \n",
    "get a better result. The first and easisest thing to do is tune the hyperparameters for the Random Forest Classifier and compare the results with the original submission. -->\n",
    "\n",
    "We can start by looking for entries in the dataset to dropout or modify to improve the performance of the model. The passenger ID contains a unique and non-null value which means that there will be no duplicates to drop. There are missing values in other columns that we can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1309\n",
      "\n",
      "Age          263\n",
      "Fare           1\n",
      "Cabin       1014\n",
      "Embarked       2\n",
      "Name: by amount, dtype: int64         \n",
      "\n",
      "Age         20.09 \n",
      "Fare         0.08 \n",
      "Cabin       77.46 \n",
      "Embarked     0.15 \n",
      "Name: by percent, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_list = [train_data.drop(\"Survived\", axis=1), test_data]\n",
    "data_list = [train_data, test_data]\n",
    "for i, dl in enumerate(data_list):\n",
    "        data_list[i].Sex = dl.Sex.apply(lambda sex: 0 if sex == \"male\" else 1)\n",
    "all_data = pd.concat(data_list)\n",
    "\n",
    "missing_vals = [all_data[col].isnull().sum() for col in all_data.columns.to_list()]\n",
    "labels = all_data.columns.to_list()\n",
    "ser = pd.Series(data=missing_vals, index=labels, name=\"by amount\")\n",
    "ser_missing = ser[ser > 0].drop(\"Survived\", axis=0)\n",
    "\n",
    "percentages = ser_missing.apply(lambda x: \"%.2f \" % (x * 100 / all_data.shape[0]))\n",
    "percentages.name = \"by percent\"\n",
    "print(f\"Total number of rows: {all_data.shape[0]}\\n\\n{ser_missing} \\\n",
    "        \\n\\n{percentages}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of missing values for `Fare` and `Embarked` column is negligible, it is best to simply drop these entries from the dataset. However, there are a considerable amount of missing values for the `Age` and `Cabin` columns. A naive approach for filling in the missing values for the columns would be to fill them in with the mean, median, or mode of the column. The better approach is to look at the relationships between `Age` and the other columns, then determine how to replace the missing values. We can apply the same principle for the `Cabin` column.\n",
    "\n",
    "The format of the cabin data will need to be changed. The cabin data is given as `{Cabin Type}{Room Number}`. The room number can be discarded but since the cabin type likely has some influence on rather a passenger survives, it should be included. To check this, we'll look at the relationship between the cabin type and survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Age     Cabin\n",
      "Survived -0.077221  0.287944\n",
      "Pclass   -0.408106 -0.563667\n",
      "Sex      -0.063645  0.133479\n",
      "Age       1.000000  0.205097\n",
      "SibSp    -0.243699 -0.009317\n",
      "Parch    -0.150917  0.034465\n",
      "Cabin     0.205097  1.000000\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "### Note: You would drop the Fare and Embarked null values\n",
    "    # dl = dl[dl[\"Fare\"].notna() & dl[\"Embarked\"].notna()]\n",
    "    # but for the competition these entries are required.\n",
    "\n",
    "    # I'll fill the `Fare` Column in with the median\n",
    "    # and bin the values for the `Fare` Column.\n",
    "for i, dl in enumerate(data_list):\n",
    "    dl[\"Fare\"] = dl[\"Fare\"].fillna(dl[\"Fare\"].median())\n",
    "    dl[\"Fare\"] = pd.qcut(dl[\"Fare\"], q=4, labels=['A','B','C','D'])\n",
    "\n",
    "    dl[\"Embarked\"] = dl[\"Embarked\"].fillna(\"S\")\n",
    "    dl[\"Cabin\"] = dl[\"Cabin\"].apply(lambda x: x[0] if pd.notna(x) else x)\n",
    "    dl[\"Cabin\"] = dl[\"Cabin\"].astype('category').cat.codes\n",
    "    data_list[i] = dl\n",
    "all_data = pd.concat(data_list)\n",
    "\n",
    "corr = all_data.corr()[[\"Age\", \"Cabin\"]].drop(\"PassengerId\", axis=0)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_copy = train_data.copy()\n",
    "train_data_copy[\"Cabin\"] = train_data_copy[\"Cabin\"].astype('category').cat.codes\n",
    "group_survive = train_data_copy.groupby(\"Cabin\")[\"Survived\"].sum()\n",
    "goup_count = train_data_copy.groupby(\"Cabin\")[\"Survived\"].count()\n",
    "\n",
    "percentages = []\n",
    "for (u, v) in zip(group_survive, goup_count):\n",
    "    percentages.append(u / v * 100)\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.bar(group_survive.index, percentages)\n",
    "plt.xlabel(\"Cabin type\")\n",
    "plt.ylabel(\"% Survived\")\n",
    "plt.axis([-1, 8, 0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pclass` appears to have a high influence on `Age` and `Cabin` column. This information can be applied to extract finer approximations based on the `Pclass` to replace the missing entries as opposed to a \"one fits all\" approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "-1    3\n",
       " 0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " 5    2\n",
       " 6    3\n",
       " 7    1\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group = all_data.groupby([\"Pclass\"])[\"Age\"].mean().astype(int)\n",
    "cabin_group = all_data.groupby([\"Cabin\"])[\"Pclass\"].agg(pd.Series.mode)\n",
    "\n",
    "for i in all_data[all_data[\"Age\"].isna()].index:\n",
    "    Pclass = all_data.iloc[i].Pclass\n",
    "    all_data.loc[i, \"Age\"] = round(age_group[Pclass])\n",
    "    \n",
    "cabin_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the % survived chart and how the `Cabin` relates to `Pclass`, we can reasonably assume that cabin 1, 3, 4, are roughly the same. We'll bin these cabins and the remaining cabins will go in a seperate bin. A `PClass` of 1 will belong to the first bin and anything else belongs to the second bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "Name: by amount, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['Cabin'] = all_data['Cabin'].replace([1,3,4], 0)\n",
    "all_data['Cabin'] = all_data['Cabin'].replace([0,2,5,6,7], 1)\n",
    "for i in all_data[all_data[\"Cabin\"] == -1].index:\n",
    "    Pclass = all_data.iloc[i].Pclass\n",
    "    all_data.loc[i, \"Cabin\"] = 0 if Pclass == 1 else 1\n",
    "\n",
    "missing_vals = [all_data[col].isnull().sum() for col in all_data.columns.to_list()]\n",
    "labels = all_data.columns.to_list()\n",
    "ser = pd.Series(data=missing_vals, index=labels, name=\"by amount\").drop(\"Survived\", axis=0)\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there are no more missing values, we can add the `Age` and `Cabin` columns to the features for the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features):\n",
    "    train_data = all_data[all_data[\"Survived\"].notna()]\n",
    "    test_data = all_data[all_data[\"Survived\"].isna()]\n",
    "\n",
    "    y = train_data[\"Survived\"]\n",
    "\n",
    "    X = pd.get_dummies(train_data[features])\n",
    "    X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "    model.fit(X, y)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions.astype(int)})\n",
    "    output.to_csv('new_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scores**\n",
    "Original Score: 0.77511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train([\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Cabin\", \"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score 0.78468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train([\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score: 0.78708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train([\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score: 0.76555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "Without tuning any of the hyperparameters for the given model, I was able to slightly improve the model by including some of the features that were initially incompatible with the `Random Forest Classifier`. Adding just `Fare` and `Embarked` resulted in a lower score. Additionally, removing `Cabin` and including the rest of the features resulted in the best score. Doing further data analysis and engineering on the features may result in meaningful changes to the scores, but changing the hyperparameters for the RFC or experimenting with other types of models is likely the better approach to improving the scores at this point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
