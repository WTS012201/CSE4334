{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "CHANNELS_D = 3\n",
    "\n",
    "img_size = 400\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"model.pth\"\n",
    "data_dir = \"~/Documents/datasets/archive/caltech101_classification/\"\n",
    "\n",
    "classes = [\"Motorcycle\", \"Airplane\", \"Schooner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_transforms(dir):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    dataset = datasets.ImageFolder(root=dir, transform=transform)\n",
    "    # concat image data (CxWxH) in tensor, discard labels\n",
    "    imgs = torch.stack([img_t for img_t, _ in dataset], dim=3)\n",
    "    # flatten the three channels of all images and take the mean\n",
    "    mean = np.array([m for m in imgs.view(3, -1).mean(dim=1)])\n",
    "    std = np.array([s for s in imgs.view(3, -1).std(dim=1)])\n",
    "\n",
    "    norm = transforms.Normalize(\n",
    "        mean = mean,\n",
    "        std = std\n",
    "    )\n",
    "    unorm = transforms.Normalize(\n",
    "        mean = -(mean/std),\n",
    "        std = (1 / std)\n",
    "    )\n",
    "    \n",
    "    return norm, unorm\n",
    "\n",
    "norm, unorm = norm_transforms(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            norm,\n",
    "        ]\n",
    "    )\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root=dir,\n",
    "        transform=transform)\n",
    "\n",
    "    train_size = int(0.6 * len(dataset))\n",
    "    test_val_size = len(dataset) - train_size\n",
    "    train_data, test_val_data = torch.utils.data.random_split(dataset, [train_size, test_val_size])\n",
    "\n",
    "    val_size = int(0.5 * len(test_val_data))\n",
    "    test_size = len(test_val_data) - val_size\n",
    "    val_data, test_data = torch.utils.data.random_split(test_val_data, [val_size, test_size])\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "train_data, val_data, test_data = load_data(\"~/Documents/datasets/archive/caltech101_classification/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_layers(num_layers, expansion):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        out_channels = expansion(in_channels)\n",
    "        # out_channels = expansion * in_channels\n",
    "        layers += [nn.Conv2d(in_channels, out_channels, kernel_size=5, padding=2)]\n",
    "        layers += [nn.ReLU()]\n",
    "        layers += [nn.MaxPool2d(2, 2)]\n",
    "        in_channels = out_channels\n",
    "\n",
    "    # num params\n",
    "    # print(((img_size // (2 ** num_layers)) ** 2) * in_channels)\n",
    "    fcl = ((img_size // (2 ** num_layers)) ** 2) * in_channels\n",
    "    layers += [nn.Flatten(1), nn.Linear(fcl, 256), nn.ReLU()]\n",
    "    layers += [nn.Linear(256, 3), nn.ReLU()]\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_layers, expansion):\n",
    "        super().__init__()\n",
    "        self.expansion = expansion\n",
    "        self.num_layers = num_layers\n",
    "        self.net = nn.Sequential(\n",
    "            gen_layers(self.num_layers, self.expansion)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, batch, epochs, lr):\n",
    "    CHANNELS_D = 3\n",
    "    # LEARNING_RATE = 1e-4\n",
    "\n",
    "    loader = DataLoader(train_data, batch_size=batch, shuffle=True, num_workers=2)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (imgs, labels) in enumerate(loader):\n",
    "            inputs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f'epoch: {epoch + 1} loss: {running_loss / batch:.3f}')\n",
    "        losses.append((epoch, float(f\"{(running_loss / batch):.3f}\")))\n",
    "        running_loss = 0.0\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def save(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, test_data):\n",
    "    with torch.no_grad():\n",
    "        figure = plt.figure(figsize=(10, 8))\n",
    "        cols, rows = 4, 4\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(1, cols * rows + 1):\n",
    "            rand = torch.randint(len(test_data), size=(1,)).item()\n",
    "            img, label = test_data[rand]\n",
    "            img_input = img.to(device).unsqueeze(0)\n",
    "\n",
    "            figure.add_subplot(rows, cols, i)\n",
    "            img = unorm(img)\n",
    "            npimg = np.transpose(img.numpy(), (1, 2, 0))\n",
    "\n",
    "            plt.title(f\"({i}) {classes[label]}\")\n",
    "            plt.axis(\"off\",)\n",
    "            plt.imshow((npimg * 255).astype(np.uint8))\n",
    "\n",
    "            pred = model(img_input).to('cpu')\n",
    "\n",
    "            _, pred = torch.max(pred.squeeze(), 0)\n",
    "    \n",
    "            print(f\"({i}) Prediction: {classes[pred.item()]}, Actual: {classes[label]}\")\n",
    "            correct += classes[pred.item()] == classes[label]\n",
    "        \n",
    "        print(f\"\\n {correct} / {cols * rows} correct -> {correct / (cols * rows) * 100} %\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, data):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "\n",
    "        for (img, label) in data:\n",
    "            img_input = img.to(device).unsqueeze(0)\n",
    "\n",
    "            pred = model(img_input).to('cpu')\n",
    "            _, pred = torch.max(pred.squeeze(), 0)\n",
    "            \n",
    "            correct += classes[pred.item()] == classes[label]\n",
    "        return round((correct / len(data) * 100), 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs, expansions = [], []\n",
    "num_layers = 5\n",
    "# recursive expressions to use for expanding feature map from conv layer (number of kernels)\n",
    "expansions.append(lambda x: x + 7)\n",
    "expansions.append(lambda x: x + 13)\n",
    "expansions.append(lambda x: x*2 if x < 20 else x + (x // 2))\n",
    "expansions.append(lambda x: x*3 if x < 50 else x + (x // 3))\n",
    "\n",
    "# for n in range(num_layers):\n",
    "#     for expr in expansions:\n",
    "#         model = CNN(n + 1, expr).to(device)\n",
    "#         losses = train(model, train_data, batch=100, epochs=25, lr=1e-4)\n",
    "#         accuracy = eval(model, val_data)\n",
    "#         runs.append((n, expr, losses, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3->9->27->81->108->144->192 accuracy: 92.771\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/will/Documents/school/cse4334/assignment2/eval.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         axs[n_lay]\u001b[39m.\u001b[39mset(xlabel\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m\"\u001b[39m, ylabel\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m plot_losses(runs)\n",
      "\u001b[1;32m/home/will/Documents/school/cse4334/assignment2/eval.ipynb Cell 9\u001b[0m in \u001b[0;36mplot_losses\u001b[0;34m(runs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     conv_seq \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m->\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(prior)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mconv_seq\u001b[39m}\u001b[39;00m\u001b[39m accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m axs[n_lay]\u001b[39m.\u001b[39mplot(\u001b[39m*\u001b[39m\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mepoch_loss), label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature Map Expansion: \u001b[39m\u001b[39m{\u001b[39;00mconv_seq\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m axs[n_lay]\u001b[39m.\u001b[39mset_title(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mn_lay \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Conv Layers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m axs[n_lay]\u001b[39m.\u001b[39mlegend()\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x2160 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#[(n, expr, [(epoch, loss)...])]\n",
    "\n",
    "def plot_losses(runs):\n",
    "    fig, axs = plt.subplots(num_layers, figsize=(12,30), gridspec_kw={'hspace': 0,})\n",
    "\n",
    "    for (n_lay, expr, epoch_loss, accuracy) in runs:\n",
    "        prior = CHANNELS_D\n",
    "        conv_seq = str(prior)\n",
    "        for i in range(n_lay+1):\n",
    "            prior = expr(prior)\n",
    "            conv_seq += f\"->{str(prior)}\"\n",
    "        print(f\"{conv_seq} accuracy: {accuracy}\")\n",
    "        axs[n_lay].plot(*zip(*epoch_loss), label=f\"Feature Map Expansion: {conv_seq}\")\n",
    "        axs[n_lay].set_title(f\"{n_lay + 1} Conv Layers\")\n",
    "        axs[n_lay].legend()\n",
    "        axs[n_lay].set(xlabel=\"Epoch\", ylabel=\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "# plot_losses(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 978.00 MiB (GPU 0; 7.93 GiB total capacity; 5.10 GiB already allocated; 417.00 MiB free; 6.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/will/Documents/school/cse4334/assignment2/eval.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m runs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m CNN(\u001b[39m2\u001b[39m, expansions[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m losses \u001b[39m=\u001b[39m train(model, train_data, batch\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(model, val_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m runs\u001b[39m.\u001b[39mappend((\u001b[39m2\u001b[39m, expr, losses, accuracy))\n",
      "\u001b[1;32m/home/will/Documents/school/cse4334/assignment2/eval.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, batch, epochs, lr)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/will/Documents/school/cse4334/assignment2/eval.ipynb Cell 10\u001b[0m in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/will/Documents/school/cse4334/assignment2/eval.ipynb#X41sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:98\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 978.00 MiB (GPU 0; 7.93 GiB total capacity; 5.10 GiB already allocated; 417.00 MiB free; 6.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# have to adjust learning rates for every n layers\n",
    "# lrs = {\n",
    "#     0: 1e-4,\n",
    "#     1: 1e-3,\n",
    "#     2: _,\n",
    "#     3: _,\n",
    "#     4: 0.05,\n",
    "# }\n",
    "runs = []\n",
    "model = CNN(2, expansions[1]).to(device)\n",
    "losses = train(model, train_data, batch=100, epochs=25, lr=1e-3)\n",
    "accuracy = eval(model, val_data)\n",
    "runs.append((2, expr, losses, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
