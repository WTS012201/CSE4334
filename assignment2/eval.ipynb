{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "CHANNELS_D = 3\n",
    "\n",
    "img_size = 256\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"model.pth\"\n",
    "data_dir = \"~/Documents/datasets/archive/caltech101_classification/\"\n",
    "\n",
    "classes = [\"Motorcycle\", \"Airplane\", \"Schooner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_transforms(dir):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    dataset = datasets.ImageFolder(root=dir, transform=transform)\n",
    "    # concate image data (CxWxH) in tensor, discard labels\n",
    "    imgs = torch.stack([img_t for img_t, _ in dataset], dim=3)\n",
    "    # flatten the three channels of all images and take the mean\n",
    "    mean = np.array([m for m in imgs.view(3, -1).mean(dim=1)])\n",
    "    std = np.array([s for s in imgs.view(3, -1).std(dim=1)])\n",
    "\n",
    "    norm = transforms.Normalize(\n",
    "        mean = mean,\n",
    "        std = std\n",
    "    )\n",
    "    unorm = transforms.Normalize(\n",
    "        mean = -(mean/std),\n",
    "        std = (1 / std)\n",
    "    )\n",
    "    \n",
    "    return norm, unorm\n",
    "\n",
    "norm, unorm = norm_transforms(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            norm,\n",
    "        ]\n",
    "    )\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root=dir,\n",
    "        transform=transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "train_data, test_data = load_data(\"~/Documents/datasets/archive/caltech101_classification/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, img_d=400, features_d=6):\n",
    "        super().__init__()\n",
    "        self.img_d = img_d\n",
    "        self.features_d = features_d\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(3, self.features_d, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(self.features_d, self.features_d * 3, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(1),\n",
    "            # (conv -> maxpool)(img_d) => (img_d/2)\n",
    "            # (conv -> maxpool)(img_d/2) => (img_d/4)\n",
    "            # (img_d/4)**2 * 3 * features_d\n",
    "            self._block(((img_d // 4) ** 2) * 3 * features_d, 128),\n",
    "            self._block(128, 64),\n",
    "            self._block(64, 3),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, batch, epochs):\n",
    "    CHANNELS_D = 3\n",
    "    LEARNING_RATE = 1e-4\n",
    "\n",
    "    loader = DataLoader(train_data, batch_size=batch, shuffle=True, num_workers=2)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (imgs, labels) in enumerate(loader):\n",
    "            inputs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f'epoch: {epoch + 1} loss: {running_loss / batch:.3f}')\n",
    "        running_loss = 0.0\n",
    "    \n",
    "    torch.save(model.state_dict(), \"model.pth\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(img_d=img_size, features_d=6).to(device)\n",
    "model = train(model, train_data, 64, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_data):\n",
    "    with torch.no_grad():\n",
    "        figure = plt.figure(figsize=(10, 8))\n",
    "        cols, rows = 4, 4\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(1, cols * rows + 1):\n",
    "            rand = torch.randint(len(test_data), size=(1,)).item()\n",
    "            img, label = test_data[rand]\n",
    "            img_input = img.to(device).unsqueeze(0)\n",
    "\n",
    "            figure.add_subplot(rows, cols, i)\n",
    "            img = unorm(img)\n",
    "            npimg = np.transpose(img.numpy(), (1, 2, 0))\n",
    "\n",
    "            plt.title(f\"({i}) {classes[label]}\")\n",
    "            plt.axis(\"off\",)\n",
    "            plt.imshow(npimg)\n",
    "            pred = model(img_input).to('cpu')\n",
    "\n",
    "            _, pred = torch.max(pred.squeeze(), 0)\n",
    "    \n",
    "            print(f\"({i}) Prediction: {classes[pred.item()]}, Actual: {classes[label]}\")\n",
    "            correct += classes[pred.item()] == classes[label]\n",
    "        \n",
    "        print(f\"\\n {correct} / {cols * rows} correct -> {correct / (cols * rows)} %\")\n",
    "        plt.show()\n",
    "        \n",
    "eval(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
