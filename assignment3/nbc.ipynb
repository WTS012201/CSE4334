{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datapath = \"~/Documents/datasets/ford_sentence/\"\n",
    "train_data = pd.read_csv(datapath + \"train_data.csv\", skip_blank_lines=True)\n",
    "#train_data = train_data[train_data.New_Sentence.notna()]\n",
    "train_data = train_data.dropna(how=\"any\")\n",
    "\n",
    "num_sentences = len(train_data.iloc[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tables = {}\n",
    "\n",
    "for type in train_data.Type:\n",
    "    if type not in class_tables:\n",
    "        class_tables[type] = train_data.loc[train_data.Type == type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking number of occurences of each word for every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "vocab_class = {}\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "for class_type, class_data in class_tables.items():\n",
    "    vocab_class[class_type] = {}\n",
    "    for sentence in class_data.New_Sentence:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = regex.sub(' ', sentence)\n",
    "        for word in sentence.split():\n",
    "            if word in vocab_class[class_type]:\n",
    "                vocab_class[class_type][word] += 1\n",
    "            else:\n",
    "                vocab_class[class_type][word] = 1\n",
    "    omitted_vocab = {key : 0 for key, val in vocab_class[class_type].items() if val >= 5}\n",
    "    vocab_class[class_type] = omitted_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_type, class_data in class_tables.items():\n",
    "    class_size = len(class_data.New_Sentence)\n",
    "    vocab = vocab_class[class_type]\n",
    "\n",
    "    for sentence in class_data.New_Sentence:\n",
    "        added = set()\n",
    "        sentence = sentence.lower()\n",
    "        sentence = regex.sub(' ', sentence)\n",
    "        for word in sentence.split():\n",
    "            if word in vocab.keys() and word not in added:\n",
    "                vocab[word] += 1        \n",
    "            added.add(word)\n",
    "    for word in vocab.keys():\n",
    "        vocab[word] /= class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(w | Responsibility)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "and               0.696926\n",
       "or                0.050534\n",
       "review            0.021892\n",
       "architecture      0.012453\n",
       "design            0.059514\n",
       "                    ...   \n",
       "categorization    0.000393\n",
       "approximately     0.000328\n",
       "rs                0.000262\n",
       "hedges            0.000131\n",
       "consignment       0.000066\n",
       "Length: 3427, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.Series(vocab_class['Responsibility'])\n",
    "print(\"P(w | Responsibility)\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBC():\n",
    "    def __init__(self, train_data) -> None:\n",
    "        self.regex = re.compile('[^a-zA-Z ]')\n",
    "        self.class_tables = self.separate_by_class(train_data)\n",
    "        self.priors = self.compute_priors(train_data)\n",
    "        self.occurences = self.compute_likelihoods()\n",
    "\n",
    "    def separate_by_class(self, train_data):\n",
    "        class_tables = {}\n",
    "\n",
    "        for type in train_data.Type:\n",
    "            if type not in class_tables:\n",
    "                class_tables[type] = train_data.loc[train_data.Type == type]\n",
    "        \n",
    "        return class_tables\n",
    "\n",
    "    def compute_priors(self, train_data):\n",
    "        priors = {}\n",
    "\n",
    "        for class_type, class_data in self.class_tables.items():\n",
    "            priors[class_type] = len(class_data[:]) / len(train_data[:])\n",
    "        \n",
    "        return priors\n",
    "    \n",
    "    def compute_likelihoods(self):\n",
    "        vocab_class = {}\n",
    "\n",
    "        for class_type, class_data in self.class_tables.items():\n",
    "            vocab_class[class_type] = {}\n",
    "            for sentence in class_data.New_Sentence:\n",
    "                sentence = sentence.lower()\n",
    "                sentence = self.regex.sub(' ', sentence)\n",
    "                for word in sentence.split():\n",
    "                    if word in vocab_class[class_type]:\n",
    "                        vocab_class[class_type][word] += 1\n",
    "                    else:\n",
    "                        vocab_class[class_type][word] = 1\n",
    "            omitted_vocab = {key : 0 for key, val in vocab_class[class_type].items() if val >= 5}\n",
    "            vocab_class[class_type] = omitted_vocab\n",
    "\n",
    "        for class_type, class_data in self.class_tables.items():\n",
    "            class_size = len(class_data.New_Sentence)\n",
    "            vocab = vocab_class[class_type]\n",
    "\n",
    "            for sentence in class_data.New_Sentence:\n",
    "                added = set()\n",
    "                sentence = sentence.lower()\n",
    "                sentence = self.regex.sub(' ', sentence)\n",
    "                for word in sentence.split():\n",
    "                    if word in vocab.keys() and word not in added:\n",
    "                        vocab[word] += 1        \n",
    "                    added.add(word)\n",
    "            for word in vocab.keys():\n",
    "                vocab[word] /= class_size\n",
    "        \n",
    "        return vocab_class\n",
    "\n",
    "    def __call__(self, sentence):\n",
    "        max_a_posteriori = (None, 0)\n",
    "\n",
    "        for class_type, prior in self.priors.items():\n",
    "            sentence = sentence.lower()\n",
    "            sentence = self.regex.sub(' ', sentence)\n",
    "            likelihood = prior\n",
    "            for word in sentence.split():\n",
    "                if word in self.occurences[class_type]:\n",
    "                    likelihood *= self.occurences[class_type][word] \n",
    "\n",
    "            print(f\"{class_type}: {likelihood}\")\n",
    "            if likelihood > max_a_posteriori[1]:\n",
    "                max_a_posteriori = (class_type, likelihood)\n",
    "        \n",
    "        return max_a_posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Responsibility': 0.2585844547642453, 'Requirement': 0.23521236568251924, 'Skill': 0.11580963357174333, 'SoftSkill': 0.1595878105826921, 'Education': 0.07694654418494289, 'Experience': 0.15385919121385716}\n",
      "Responsibility: 8.668542287165756e-27\n",
      "Requirement: 3.6976258720270046e-26\n",
      "Skill: 8.387046472103041e-29\n",
      "SoftSkill: 2.911311176851286e-22\n",
      "Education: 1.442102453747357e-17\n",
      "Experience: 3.841821441254866e-28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Education', 1.442102453747357e-17)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NBC(train_data)\n",
    "print(model.priors)\n",
    "model(\"Productivity solutions include a mix of products, from rugged mobile computers, voice enabled softwa...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
