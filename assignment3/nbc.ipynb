{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datapath = \"~/Documents/datasets/ford_sentence/\"\n",
    "data = pd.read_csv(datapath + \"train_data.csv\", skip_blank_lines=True)\n",
    "#data = data[data.New_Sentence.notna()]\n",
    "data = data.dropna(how=\"any\")\n",
    "\n",
    "num_sentences = len(data.iloc[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tables = {}\n",
    "\n",
    "for type in data.Type:\n",
    "    if type not in class_tables:\n",
    "        class_tables[type] = data.loc[data.Type == type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking number of occurences for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "vocab_class = {}\n",
    "regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "for class_type, class_data in class_tables.items():\n",
    "    vocab_class[class_type] = {}\n",
    "    for sentence in class_data.New_Sentence:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = regex.sub(' ', sentence)\n",
    "        for word in sentence.split():\n",
    "            if word in vocab_class[class_type]:\n",
    "                vocab_class[class_type][word] += 1\n",
    "            else:\n",
    "                vocab_class[class_type][word] = 1\n",
    "    omitted_vocab = {key : 0 for key, val in vocab_class[class_type].items() if val >= 5}\n",
    "    vocab_class[class_type] = omitted_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_type, class_data in class_tables.items():\n",
    "    class_size = len(class_data.New_Sentence)\n",
    "    vocab = vocab_class[class_type]\n",
    "\n",
    "    for sentence in class_data.New_Sentence:\n",
    "        added = set()\n",
    "        sentence = sentence.lower()\n",
    "        sentence = regex.sub(' ', sentence)\n",
    "        for word in sentence.split():\n",
    "            if word in vocab.keys() and word not in added:\n",
    "                if word in added:\n",
    "                    continue\n",
    "                vocab[word] += 1        \n",
    "            added.add(word)\n",
    "    for word in vocab.keys():\n",
    "        vocab[word] /= class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and               0.696926\n",
       "or                0.050534\n",
       "review            0.021892\n",
       "architecture      0.012453\n",
       "design            0.059514\n",
       "                    ...   \n",
       "categorization    0.000393\n",
       "approximately     0.000328\n",
       "rs                0.000262\n",
       "hedges            0.000131\n",
       "consignment       0.000066\n",
       "Length: 3427, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.Series(vocab_class['Responsibility'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
